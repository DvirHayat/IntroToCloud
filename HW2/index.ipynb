{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DvirHayat/IntroToCloud/blob/main/HW2/index.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN0yECnFQ-Qx",
        "outputId": "225aaecb-f796-4733-9faf-86abc01a1d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('context', 676), ('type', 656), ('keyboard', 631), ('shortcut', 631), ('plan', 626), ('part', 524), ('studio', 369), ('assembl', 279), ('draw', 226), ('sketch', 220)]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Fetch the URL and parse as an HTML\n",
        "def fetch_page(url):\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        return soup\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Get text from soup and add count its appearance\n",
        "def index_words(soup):\n",
        "    index = {}\n",
        "    words = re.findall(r'\\w+', soup.get_text())\n",
        "    for word in words:\n",
        "        word = word.lower()\n",
        "        if word in index:\n",
        "            index[word] += 1\n",
        "        else:\n",
        "            index[word] = 1\n",
        "    return index\n",
        "\n",
        "# Removes stop words from all words\n",
        "def remove_stop_words(index):\n",
        "    # stop_words = {'a', 'an', 'the', 'and', 'or', 'in', 'on', 'at'}\n",
        "    stop_words = {'a', 'an', 'the', 'and', 'or', 'in', 'on', 'at', 'to', 'see', 'also', 'all', 'n', 'of'}  # Another version of stop words to remove from counting.\n",
        "    for stop_word in stop_words:\n",
        "        if stop_word in index:\n",
        "            del index[stop_word]\n",
        "    return index\n",
        "\n",
        "# Stemm the words\n",
        "def apply_stemming(index):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_index = {}\n",
        "    for word, count in index.items():\n",
        "        stemmed_word = stemmer.stem(word)\n",
        "        if stemmed_word in stemmed_index:\n",
        "            stemmed_index[stemmed_word] += count\n",
        "        else:\n",
        "            stemmed_index[stemmed_word] = count\n",
        "    return stemmed_index\n",
        "\n",
        "# URL of the glossary page\n",
        "url = \"https://cad.onshape.com/help/Content/Glossary/glossary.htm\"\n",
        "\n",
        "# Fetch and process the page\n",
        "soup = fetch_page(url)\n",
        "if soup:\n",
        "    # Extract and index the words from the webpage\n",
        "    index = index_words(soup)\n",
        "\n",
        "    # Remove stop words\n",
        "    cleaned_index = remove_stop_words(index)\n",
        "\n",
        "    # Apply stemming to the indexed words\n",
        "    stemmed_index = apply_stemming(cleaned_index)\n",
        "\n",
        "    # Identify the 10 most frequent words\n",
        "    top_10_words = sorted(stemmed_index.items(), key=lambda item: item[1], reverse=True)[:10]\n",
        "    print(top_10_words)\n",
        "else:\n",
        "    print(\"Failed to fetch the webpage content.\")\n"
      ]
    }
  ]
}